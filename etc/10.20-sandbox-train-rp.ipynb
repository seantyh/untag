{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1f8db403-c251-482c-ba9a-b0eb2a62c91a",
   "metadata": {},
   "source": [
    "## Environment Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5972485b-f909-4059-9bea-163d2d4ce7cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bb2001b2-e4f4-4e2e-b7a0-610ba3fa5c11",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "if \"../src\" not in sys.path:\n",
    "    sys.path.append(\"../src\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a5244018-05c1-4761-ad7b-f9d6b83ae3ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import random\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "import torch\n",
    "import datasets\n",
    "from datasets import Dataset, load_metric\n",
    "from torch.utils.data import (DataLoader, RandomSampler, SequentialSampler)\n",
    "from transformers import AutoModelForMultipleChoice, BertTokenizerFast\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "934bc723-c3de-495c-b52f-57e6916a6153",
   "metadata": {},
   "outputs": [],
   "source": [
    "counter = 0\n",
    "SESS_NAME = datetime.now().strftime(\"%y%m%d%H%M\")\n",
    "datadir = \"../data\"\n",
    "modeldir = \"../data/models\"\n",
    "###########################\n",
    "datafile = f\"{datadir}/refined_dot_type_5.0.csv\"\n",
    "dataset_dir = f\"{datadir}/PT2_encoded_dataset\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "70193523-4b3e-492e-b6ea-f4dfb39bb209",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "455"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_dataset = datasets.load_from_disk(dataset_dir)\n",
    "len(encoded_dataset[\"train\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ecf692c1-9c3f-49b9-91ec-b147b3ccfbc4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type_class</th>\n",
       "      <th>eng word</th>\n",
       "      <th>word</th>\n",
       "      <th>pos</th>\n",
       "      <th>instance</th>\n",
       "      <th>src</th>\n",
       "      <th>dot_type_2</th>\n",
       "      <th>dot_type_1</th>\n",
       "      <th>label</th>\n",
       "      <th>zh_type_class</th>\n",
       "      <th>zh_dot_type</th>\n",
       "      <th>zh_dot_type_2</th>\n",
       "      <th>zh_dot_gloss</th>\n",
       "      <th>is_2choice</th>\n",
       "      <th>is_one_ans</th>\n",
       "      <th>class_selector</th>\n",
       "      <th>__index_level_0__</th>\n",
       "      <th>input_ids</th>\n",
       "      <th>token_type_ids</th>\n",
       "      <th>attention_mask</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>event,human</td>\n",
       "      <td>appointment</td>\n",
       "      <td>個案</td>\n",
       "      <td>Na</td>\n",
       "      <td>這棟預售&lt;個案&gt;基地面積五百零八坪屬商三土地。</td>\n",
       "      <td>ASBC</td>\n",
       "      <td>event</td>\n",
       "      <td>event</td>\n",
       "      <td>0</td>\n",
       "      <td>事件,人類</td>\n",
       "      <td>事件</td>\n",
       "      <td>事件</td>\n",
       "      <td>事情、事項。</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>[[6], [8]]</td>\n",
       "      <td>251</td>\n",
       "      <td>[[101, 6857, 3477, 7521, 1545, 133, 943, 3428,...</td>\n",
       "      <td>[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...</td>\n",
       "      <td>[[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>act,proposition</td>\n",
       "      <td>allegation</td>\n",
       "      <td>宣稱</td>\n",
       "      <td>nom</td>\n",
       "      <td>在不能提供證據的前提下，我對他的&lt;宣稱&gt;感到懷疑。</td>\n",
       "      <td>CWN2</td>\n",
       "      <td>proposition</td>\n",
       "      <td>proposition</td>\n",
       "      <td>1</td>\n",
       "      <td>行為,命題</td>\n",
       "      <td>命題</td>\n",
       "      <td>命題</td>\n",
       "      <td>邏輯學上指表達判斷的語句。通常以直陳語句或假定句表達。</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>[[2], [9]]</td>\n",
       "      <td>33</td>\n",
       "      <td>[[101, 1762, 679, 5543, 2990, 897, 6349, 3087,...</td>\n",
       "      <td>[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...</td>\n",
       "      <td>[[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        type_class     eng word word  pos                   instance   src  \\\n",
       "0      event,human  appointment   個案   Na    這棟預售<個案>基地面積五百零八坪屬商三土地。  ASBC   \n",
       "1  act,proposition   allegation   宣稱  nom  在不能提供證據的前提下，我對他的<宣稱>感到懷疑。  CWN2   \n",
       "\n",
       "    dot_type_2   dot_type_1  label zh_type_class zh_dot_type zh_dot_type_2  \\\n",
       "0        event        event      0         事件,人類          事件            事件   \n",
       "1  proposition  proposition      1         行為,命題          命題            命題   \n",
       "\n",
       "                  zh_dot_gloss  is_2choice  is_one_ans class_selector  \\\n",
       "0                       事情、事項。        True        True     [[6], [8]]   \n",
       "1  邏輯學上指表達判斷的語句。通常以直陳語句或假定句表達。        True        True     [[2], [9]]   \n",
       "\n",
       "   __index_level_0__                                          input_ids  \\\n",
       "0                251  [[101, 6857, 3477, 7521, 1545, 133, 943, 3428,...   \n",
       "1                 33  [[101, 1762, 679, 5543, 2990, 897, 6349, 3087,...   \n",
       "\n",
       "                                      token_type_ids  \\\n",
       "0  [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...   \n",
       "1  [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...   \n",
       "\n",
       "                                      attention_mask  \n",
       "0  [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,...  \n",
       "1  [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_dataset[\"train\"].select([0,2]).to_pandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b3ef159-f3de-4d40-9071-c3e6521c410e",
   "metadata": {},
   "source": [
    "## Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2ff06092-a163-4db0-9b36-9911526da19b",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizerFast.from_pretrained('bert-base-chinese')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "75c24db8-e273-4768-a887-6d843cb47ad3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "@dataclass\n",
    "class DataCollatorForMultipleChoice:\n",
    "    \"\"\"\n",
    "    Data collator that will dynamically pad the inputs for multiple choice received.\n",
    "    \"\"\"\n",
    "    tokenizer = tokenizer\n",
    "    padding, trunc = True, True\n",
    "    max_length =  None\n",
    "    pad_to_multiple_of = None\n",
    "    def __init__(self, device=torch.device(\"cpu\")):\n",
    "        self.device = device\n",
    "        \n",
    "    def __call__(self, features):\n",
    "        label_name = \"label\" if \"label\" in features[0].keys() else \"labels\"\n",
    "        pin_label = True if \"label\" in features[0].keys() else False\n",
    "        # print(\"pinned label?\", pin_label) # whether label column is correctly pinpointed \n",
    "        labels = [feature.pop(label_name) for feature in features]\n",
    "        seq_classes = [feature.pop('class_selector') for feature in features]\n",
    "        batch_size = len(features)\n",
    "        num_choices = len(features[0][\"input_ids\"])\n",
    "        accepted_keys = [\"input_ids\", \"attention_mask\", \"label\", \"token_type_ids\", 'class_selector']\n",
    "        flattened_features = [[{k: v[i] for k, v in feature.items() if k in accepted_keys} \n",
    "                               for i in range(num_choices)] for feature in features]        \n",
    "        flattened_features = sum(flattened_features, [])\n",
    "        \n",
    "        batch = self.tokenizer.pad(\n",
    "            flattened_features,\n",
    "            padding= \"longest\",\n",
    "            max_length= self.max_length,\n",
    "            pad_to_multiple_of=self.pad_to_multiple_of,\n",
    "            return_tensors=\"pt\",\n",
    "        )\n",
    "    \n",
    "        # filtering\n",
    "        # Un-flatten\n",
    "        batch = {k: v.view(batch_size, num_choices, -1) for k, v in batch.items() if k in accepted_keys}        \n",
    "    \n",
    "        # prompt selectors\n",
    "        batch[\"class_selector\"] = torch.tensor(seq_classes)\n",
    "        batch[\"labels\"] = torch.tensor(labels, dtype=torch.int64)\n",
    "          \n",
    "        batch = {k: v.to(self.device) for k, v in batch.items()}\n",
    "        return batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "458e8745-7afe-47aa-9036-1f40be4b2b75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('input_ids', torch.Size([2, 2, 33])),\n",
       " ('token_type_ids', torch.Size([2, 2, 33])),\n",
       " ('attention_mask', torch.Size([2, 2, 33])),\n",
       " ('class_selector', torch.Size([2, 2, 1])),\n",
       " ('labels', torch.Size([2]))]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features = [{k: v for k, v in encoded_dataset[\"train\"][i].items()} for i in range(2)]\n",
    "batch = DataCollatorForMultipleChoice()(features)\n",
    "[(k, v.shape) for k, v in batch.items()]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d66c93f-d7e5-4762-ae5f-1ac7c8a93702",
   "metadata": {},
   "source": [
    "## Setting up RP model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6518ed99-9304-4479-a8c7-d09c2dfd6a11",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn\n",
    "import torch.optim as optim\n",
    "from torch.nn import CrossEntropyLoss\n",
    "from transformers import BertModel, BertPreTrainedModel\n",
    "from transformers.modeling_outputs import MultipleChoiceModelOutput\n",
    "\n",
    "from pt_multiple_choice import BertPromptForMultipleChoice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ae8b663d-9b07-4f3e-93fe-332d750d579b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = encoded_dataset['train']\n",
    "metric = datasets.load_metric(\"accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "51e8ded3-25e8-42cb-bab3-af5eea922539",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[[ 101, 6857, 3477, 7521, 1545,  133,  943, 3428,  135, 1825],\n",
       "          [ 101, 6857, 3477, 7521, 1545,  133,  943, 3428,  135, 1825]],\n",
       " \n",
       "         [[ 101, 2113, 4242, 2013,  791, 2399, 8031, 3299,  819, 5647],\n",
       "          [ 101, 2113, 4242, 2013,  791, 2399, 8031, 3299,  819, 5647]]]),\n",
       " 'token_type_ids': tensor([[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "          [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]],\n",
       " \n",
       "         [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "          [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]]),\n",
       " 'attention_mask': tensor([[[1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "          [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]],\n",
       " \n",
       "         [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "          [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]]),\n",
       " 'class_selector': tensor([[[6],\n",
       "          [8]],\n",
       " \n",
       "         [[6],\n",
       "          [3]]]),\n",
       " 'labels': tensor([0, 0])}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "{k: v[...,:10] for k, v in batch.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3e8f3485-8fc2-4917-b96e-b582ed6c34b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- model params --\n",
    "model_name = 'prompt-tuning-v2'\n",
    "numchoices = 2\n",
    "# -- training hypers --\n",
    "batchsize = 6\n",
    "lr = 2e-5\n",
    "epochs = 1\n",
    "wd = 0.005\n",
    "warmup_ratio = 0.1\n",
    "myseed = 1126"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "accd3b79-72d8-4149-a600-2a8b321a16e0",
   "metadata": {},
   "source": [
    "## Manual training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b1de0c03-2eb8-4a69-aece-25570616f50a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import islice\n",
    "from torch.utils.tensorboard import SummaryWriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1becf183-0db5-4217-89ab-8f4c72259e86",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-chinese were not used when initializing BertPromptForMultipleChoice: ['cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight']\n",
      "- This IS expected if you are initializing BertPromptForMultipleChoice from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertPromptForMultipleChoice from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertPromptForMultipleChoice were not initialized from the model checkpoint at bert-base-chinese and are newly initialized: ['prefix_encoder.weight', 'classifier.weight', 'embeddings.token_type_embeddings.weight', 'classifier.bias', 'embeddings.LayerNorm.bias', 'embeddings.position_embeddings.weight', 'embeddings.word_embeddings.weight', 'embeddings.LayerNorm.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "** total param is 29953\n",
      "** train bert? False\n"
     ]
    }
   ],
   "source": [
    "batch_size = 6\n",
    "lr = 1e-4\n",
    "n_tokens = 2\n",
    "config = {\n",
    "    'n_tokens': n_tokens,\n",
    "    'n_class':19,\n",
    "    'numchoices':2,\n",
    "    'train_bert': False\n",
    "}\n",
    "counter += 1\n",
    "writer = SummaryWriter(f\"../data/tblogs/run_{SESS_NAME}_{counter}\")\n",
    "writer.add_hparams(dict(batch_size=batch_size, lr=lr, n_tokens=n_tokens), {})\n",
    "model = BertPromptForMultipleChoice.from_pretrained('bert-base-chinese', config).to(\"cuda\")\n",
    "optimizer = optim.AdamW(model.parameters(), lr=lr)\n",
    "loader = DataLoader(train_dataset, shuffle=False, collate_fn=DataCollatorForMultipleChoice(\"cuda\"), batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "338a83dc-2a51-40f5-befb-105cd8e646fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "batches = list(islice(loader, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "16bc49d5-0f96-4674-9a81-4f07077277c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'input_ids': torch.Size([6, 2, 57]),\n",
       "  'token_type_ids': torch.Size([6, 2, 57]),\n",
       "  'attention_mask': torch.Size([6, 2, 57]),\n",
       "  'class_selector': torch.Size([6, 2, 1]),\n",
       "  'labels': torch.Size([6])},\n",
       " {'input_ids': torch.Size([6, 2, 69]),\n",
       "  'token_type_ids': torch.Size([6, 2, 69]),\n",
       "  'attention_mask': torch.Size([6, 2, 69]),\n",
       "  'class_selector': torch.Size([6, 2, 1]),\n",
       "  'labels': torch.Size([6])}]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[{k: v.shape for k,v in batch.items()} for batch in batches]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "44df1c81-97fc-4471-bf23-a5ffd18ff046",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../data/tblogs/run_2203120931_1\n"
     ]
    }
   ],
   "source": [
    "print(writer.log_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "15755c26-52fe-4fa2-af8a-82910bb1a96d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "98bd762820374437866b5ff02ae7274f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "loss_vec = []\n",
    "from tqdm.auto import tqdm\n",
    "step_i = 0\n",
    "for _ in tqdm(range(100)):\n",
    "    for batch in batches:        \n",
    "        optimizer.zero_grad()\n",
    "        out = model(**batch)\n",
    "        loss = out.loss\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        loss_vec.append(loss.item())\n",
    "        writer.add_scalar(\"Loss/train\", loss.item(), step_i)      \n",
    "        step_i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b26ab933-dbfe-4faa-86ff-e5f64bd27932",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f0ebb25ea00>]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "plt.plot(loss_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6af35693-9651-4d62-bcd9-f7ea8eb66af2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "word_embeddings.weight False\n",
      "position_embeddings.weight False\n",
      "token_type_embeddings.weight False\n",
      "LayerNorm.weight False\n",
      "LayerNorm.bias False\n"
     ]
    }
   ],
   "source": [
    "for param_name, param in model.bert.embeddings.named_parameters():\n",
    "    print(param_name, param.requires_grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3646cae-11bb-4ed8-b86e-945fdeed1937",
   "metadata": {},
   "source": [
    "## With 🤗 Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "58f1ea84-7554-43c3-a966-3002880e2710",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(eval_predictions):\n",
    "    predictions, label_ids = eval_predictions\n",
    "    preds = np.argmax(predictions, axis=1)\n",
    "    return {'accuracy': (preds == label_ids).astype(np.float32).mean().item()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "cf3ca613-e1d4-4036-b1e7-1ad6ca77e9f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch: setting up devices\n"
     ]
    }
   ],
   "source": [
    "epochs = 20\n",
    "batchsize = 6\n",
    "lr = 5e-4\n",
    "n_tokens = 12\n",
    "scheduler_type = \"linear\"\n",
    "wd = 0.005\n",
    "warmup_ratio = 0.1\n",
    "\n",
    "config = {\n",
    "    'n_tokens': n_tokens,\n",
    "    'n_class':19,\n",
    "    'numchoices':2,\n",
    "    'train_bert': False\n",
    "}\n",
    "\n",
    "from transformers import TrainingArguments, Trainer\n",
    "args = TrainingArguments(\n",
    "    model_name, \n",
    "    learning_rate=lr,\n",
    "    per_device_train_batch_size=batchsize,\n",
    "    per_device_eval_batch_size=batchsize,\n",
    "    num_train_epochs=epochs,\n",
    "    gradient_accumulation_steps=1, \n",
    "    weight_decay=wd,\n",
    "    warmup_ratio = warmup_ratio,\n",
    "    lr_scheduler_type=scheduler_type,\n",
    "    logging_strategy=\"epoch\",\n",
    "    evaluation_strategy = \"epoch\",\n",
    "    save_strategy = \"epoch\",\n",
    "    report_to=\"tensorboard\",\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"eval_accuracy\",\n",
    "    seed = myseed\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "1a9bdb8b-0fc9-471b-8408-aae1b3f10303",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file https://huggingface.co/bert-base-chinese/resolve/main/config.json from cache at /home/seantyh/.cache/huggingface/transformers/6cc404ca8136bc87bae0fb24f2259904943d776a6c5ddc26598bbdc319476f42.0f9bcd8314d841c06633e7b92b04509f1802c16796ee67b0f1177065739e24ae\n",
      "Model config BertConfig {\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"directionality\": \"bidi\",\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"pooler_fc_size\": 768,\n",
      "  \"pooler_num_attention_heads\": 12,\n",
      "  \"pooler_num_fc_layers\": 3,\n",
      "  \"pooler_size_per_head\": 128,\n",
      "  \"pooler_type\": \"first_token_transform\",\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.15.0\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 21128\n",
      "}\n",
      "\n",
      "loading weights file https://huggingface.co/bert-base-chinese/resolve/main/pytorch_model.bin from cache at /home/seantyh/.cache/huggingface/transformers/58592490276d9ed1e8e33f3c12caf23000c22973cb2b3218c641bd74547a1889.fabda197bfe5d6a318c2833172d6757ccc7e49f692cb949a6fabf560cee81508\n",
      "Some weights of the model checkpoint at bert-base-chinese were not used when initializing BertPromptForMultipleChoice: ['cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight']\n",
      "- This IS expected if you are initializing BertPromptForMultipleChoice from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertPromptForMultipleChoice from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertPromptForMultipleChoice were not initialized from the model checkpoint at bert-base-chinese and are newly initialized: ['prefix_encoder.weight', 'classifier.weight', 'embeddings.token_type_embeddings.weight', 'classifier.bias', 'embeddings.LayerNorm.bias', 'embeddings.position_embeddings.weight', 'embeddings.word_embeddings.weight', 'embeddings.LayerNorm.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "** total param is 175873\n",
      "** train bert? False\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model = BertPromptForMultipleChoice.from_pretrained('bert-base-chinese', config).to(\"cuda\")\n",
    "trainer = Trainer(\n",
    "    model,\n",
    "    args,\n",
    "    train_dataset=encoded_dataset[\"train\"],\n",
    "    eval_dataset=encoded_dataset[\"test\"],\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=DataCollatorForMultipleChoice(),\n",
    "    compute_metrics=compute_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "657a0bb4-264c-4868-ae29-0187f529c853",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the training set  don't have a corresponding argument in `BertPromptForMultipleChoice.forward` and have been ignored: is_2choice, src, word, instance, zh_dot_type, dot_type_2, eng word, zh_dot_gloss, zh_type_class, type_class, zh_dot_type_2, is_one_ans, pos, __index_level_0__, dot_type_1.\n",
      "***** Running training *****\n",
      "  Num examples = 455\n",
      "  Num Epochs = 20\n",
      "  Instantaneous batch size per device = 6\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 6\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 1520\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1520' max='1520' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1520/1520 00:47, Epoch 20/20]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.721200</td>\n",
       "      <td>0.700884</td>\n",
       "      <td>0.517544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.697700</td>\n",
       "      <td>0.689502</td>\n",
       "      <td>0.587719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.684800</td>\n",
       "      <td>0.756923</td>\n",
       "      <td>0.482456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.664400</td>\n",
       "      <td>0.736348</td>\n",
       "      <td>0.552632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.646300</td>\n",
       "      <td>0.757984</td>\n",
       "      <td>0.587719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.607000</td>\n",
       "      <td>0.681908</td>\n",
       "      <td>0.578947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.620100</td>\n",
       "      <td>0.762686</td>\n",
       "      <td>0.552632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.605500</td>\n",
       "      <td>0.714317</td>\n",
       "      <td>0.614035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.576300</td>\n",
       "      <td>0.738288</td>\n",
       "      <td>0.587719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.561200</td>\n",
       "      <td>0.671184</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.554900</td>\n",
       "      <td>0.721937</td>\n",
       "      <td>0.622807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.526400</td>\n",
       "      <td>0.672819</td>\n",
       "      <td>0.675439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.512100</td>\n",
       "      <td>0.722946</td>\n",
       "      <td>0.675439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.475900</td>\n",
       "      <td>0.678874</td>\n",
       "      <td>0.640351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.456900</td>\n",
       "      <td>0.737730</td>\n",
       "      <td>0.684211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>0.450300</td>\n",
       "      <td>0.747955</td>\n",
       "      <td>0.684211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>0.404700</td>\n",
       "      <td>0.765114</td>\n",
       "      <td>0.701754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>0.381200</td>\n",
       "      <td>0.789948</td>\n",
       "      <td>0.719298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>0.406000</td>\n",
       "      <td>0.777960</td>\n",
       "      <td>0.719298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.392400</td>\n",
       "      <td>0.786845</td>\n",
       "      <td>0.701754</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set  don't have a corresponding argument in `BertPromptForMultipleChoice.forward` and have been ignored: is_2choice, src, word, instance, zh_dot_type, dot_type_2, eng word, zh_dot_gloss, zh_type_class, type_class, zh_dot_type_2, is_one_ans, pos, __index_level_0__, dot_type_1.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 114\n",
      "  Batch size = 6\n",
      "Saving model checkpoint to prompt-tuning-v2/checkpoint-76\n",
      "Configuration saved in prompt-tuning-v2/checkpoint-76/config.json\n",
      "Model weights saved in prompt-tuning-v2/checkpoint-76/pytorch_model.bin\n",
      "tokenizer config file saved in prompt-tuning-v2/checkpoint-76/tokenizer_config.json\n",
      "Special tokens file saved in prompt-tuning-v2/checkpoint-76/special_tokens_map.json\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `BertPromptForMultipleChoice.forward` and have been ignored: is_2choice, src, word, instance, zh_dot_type, dot_type_2, eng word, zh_dot_gloss, zh_type_class, type_class, zh_dot_type_2, is_one_ans, pos, __index_level_0__, dot_type_1.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 114\n",
      "  Batch size = 6\n",
      "Saving model checkpoint to prompt-tuning-v2/checkpoint-152\n",
      "Configuration saved in prompt-tuning-v2/checkpoint-152/config.json\n",
      "Model weights saved in prompt-tuning-v2/checkpoint-152/pytorch_model.bin\n",
      "tokenizer config file saved in prompt-tuning-v2/checkpoint-152/tokenizer_config.json\n",
      "Special tokens file saved in prompt-tuning-v2/checkpoint-152/special_tokens_map.json\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `BertPromptForMultipleChoice.forward` and have been ignored: is_2choice, src, word, instance, zh_dot_type, dot_type_2, eng word, zh_dot_gloss, zh_type_class, type_class, zh_dot_type_2, is_one_ans, pos, __index_level_0__, dot_type_1.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 114\n",
      "  Batch size = 6\n",
      "Saving model checkpoint to prompt-tuning-v2/checkpoint-228\n",
      "Configuration saved in prompt-tuning-v2/checkpoint-228/config.json\n",
      "Model weights saved in prompt-tuning-v2/checkpoint-228/pytorch_model.bin\n",
      "tokenizer config file saved in prompt-tuning-v2/checkpoint-228/tokenizer_config.json\n",
      "Special tokens file saved in prompt-tuning-v2/checkpoint-228/special_tokens_map.json\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `BertPromptForMultipleChoice.forward` and have been ignored: is_2choice, src, word, instance, zh_dot_type, dot_type_2, eng word, zh_dot_gloss, zh_type_class, type_class, zh_dot_type_2, is_one_ans, pos, __index_level_0__, dot_type_1.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 114\n",
      "  Batch size = 6\n",
      "Saving model checkpoint to prompt-tuning-v2/checkpoint-304\n",
      "Configuration saved in prompt-tuning-v2/checkpoint-304/config.json\n",
      "Model weights saved in prompt-tuning-v2/checkpoint-304/pytorch_model.bin\n",
      "tokenizer config file saved in prompt-tuning-v2/checkpoint-304/tokenizer_config.json\n",
      "Special tokens file saved in prompt-tuning-v2/checkpoint-304/special_tokens_map.json\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `BertPromptForMultipleChoice.forward` and have been ignored: is_2choice, src, word, instance, zh_dot_type, dot_type_2, eng word, zh_dot_gloss, zh_type_class, type_class, zh_dot_type_2, is_one_ans, pos, __index_level_0__, dot_type_1.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 114\n",
      "  Batch size = 6\n",
      "Saving model checkpoint to prompt-tuning-v2/checkpoint-380\n",
      "Configuration saved in prompt-tuning-v2/checkpoint-380/config.json\n",
      "Model weights saved in prompt-tuning-v2/checkpoint-380/pytorch_model.bin\n",
      "tokenizer config file saved in prompt-tuning-v2/checkpoint-380/tokenizer_config.json\n",
      "Special tokens file saved in prompt-tuning-v2/checkpoint-380/special_tokens_map.json\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `BertPromptForMultipleChoice.forward` and have been ignored: is_2choice, src, word, instance, zh_dot_type, dot_type_2, eng word, zh_dot_gloss, zh_type_class, type_class, zh_dot_type_2, is_one_ans, pos, __index_level_0__, dot_type_1.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 114\n",
      "  Batch size = 6\n",
      "Saving model checkpoint to prompt-tuning-v2/checkpoint-456\n",
      "Configuration saved in prompt-tuning-v2/checkpoint-456/config.json\n",
      "Model weights saved in prompt-tuning-v2/checkpoint-456/pytorch_model.bin\n",
      "tokenizer config file saved in prompt-tuning-v2/checkpoint-456/tokenizer_config.json\n",
      "Special tokens file saved in prompt-tuning-v2/checkpoint-456/special_tokens_map.json\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `BertPromptForMultipleChoice.forward` and have been ignored: is_2choice, src, word, instance, zh_dot_type, dot_type_2, eng word, zh_dot_gloss, zh_type_class, type_class, zh_dot_type_2, is_one_ans, pos, __index_level_0__, dot_type_1.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 114\n",
      "  Batch size = 6\n",
      "Saving model checkpoint to prompt-tuning-v2/checkpoint-532\n",
      "Configuration saved in prompt-tuning-v2/checkpoint-532/config.json\n",
      "Model weights saved in prompt-tuning-v2/checkpoint-532/pytorch_model.bin\n",
      "tokenizer config file saved in prompt-tuning-v2/checkpoint-532/tokenizer_config.json\n",
      "Special tokens file saved in prompt-tuning-v2/checkpoint-532/special_tokens_map.json\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `BertPromptForMultipleChoice.forward` and have been ignored: is_2choice, src, word, instance, zh_dot_type, dot_type_2, eng word, zh_dot_gloss, zh_type_class, type_class, zh_dot_type_2, is_one_ans, pos, __index_level_0__, dot_type_1.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 114\n",
      "  Batch size = 6\n",
      "Saving model checkpoint to prompt-tuning-v2/checkpoint-608\n",
      "Configuration saved in prompt-tuning-v2/checkpoint-608/config.json\n",
      "Model weights saved in prompt-tuning-v2/checkpoint-608/pytorch_model.bin\n",
      "tokenizer config file saved in prompt-tuning-v2/checkpoint-608/tokenizer_config.json\n",
      "Special tokens file saved in prompt-tuning-v2/checkpoint-608/special_tokens_map.json\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `BertPromptForMultipleChoice.forward` and have been ignored: is_2choice, src, word, instance, zh_dot_type, dot_type_2, eng word, zh_dot_gloss, zh_type_class, type_class, zh_dot_type_2, is_one_ans, pos, __index_level_0__, dot_type_1.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 114\n",
      "  Batch size = 6\n",
      "Saving model checkpoint to prompt-tuning-v2/checkpoint-684\n",
      "Configuration saved in prompt-tuning-v2/checkpoint-684/config.json\n",
      "Model weights saved in prompt-tuning-v2/checkpoint-684/pytorch_model.bin\n",
      "tokenizer config file saved in prompt-tuning-v2/checkpoint-684/tokenizer_config.json\n",
      "Special tokens file saved in prompt-tuning-v2/checkpoint-684/special_tokens_map.json\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `BertPromptForMultipleChoice.forward` and have been ignored: is_2choice, src, word, instance, zh_dot_type, dot_type_2, eng word, zh_dot_gloss, zh_type_class, type_class, zh_dot_type_2, is_one_ans, pos, __index_level_0__, dot_type_1.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 114\n",
      "  Batch size = 6\n",
      "Saving model checkpoint to prompt-tuning-v2/checkpoint-760\n",
      "Configuration saved in prompt-tuning-v2/checkpoint-760/config.json\n",
      "Model weights saved in prompt-tuning-v2/checkpoint-760/pytorch_model.bin\n",
      "tokenizer config file saved in prompt-tuning-v2/checkpoint-760/tokenizer_config.json\n",
      "Special tokens file saved in prompt-tuning-v2/checkpoint-760/special_tokens_map.json\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `BertPromptForMultipleChoice.forward` and have been ignored: is_2choice, src, word, instance, zh_dot_type, dot_type_2, eng word, zh_dot_gloss, zh_type_class, type_class, zh_dot_type_2, is_one_ans, pos, __index_level_0__, dot_type_1.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 114\n",
      "  Batch size = 6\n",
      "Saving model checkpoint to prompt-tuning-v2/checkpoint-836\n",
      "Configuration saved in prompt-tuning-v2/checkpoint-836/config.json\n",
      "Model weights saved in prompt-tuning-v2/checkpoint-836/pytorch_model.bin\n",
      "tokenizer config file saved in prompt-tuning-v2/checkpoint-836/tokenizer_config.json\n",
      "Special tokens file saved in prompt-tuning-v2/checkpoint-836/special_tokens_map.json\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `BertPromptForMultipleChoice.forward` and have been ignored: is_2choice, src, word, instance, zh_dot_type, dot_type_2, eng word, zh_dot_gloss, zh_type_class, type_class, zh_dot_type_2, is_one_ans, pos, __index_level_0__, dot_type_1.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 114\n",
      "  Batch size = 6\n",
      "Saving model checkpoint to prompt-tuning-v2/checkpoint-912\n",
      "Configuration saved in prompt-tuning-v2/checkpoint-912/config.json\n",
      "Model weights saved in prompt-tuning-v2/checkpoint-912/pytorch_model.bin\n",
      "tokenizer config file saved in prompt-tuning-v2/checkpoint-912/tokenizer_config.json\n",
      "Special tokens file saved in prompt-tuning-v2/checkpoint-912/special_tokens_map.json\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `BertPromptForMultipleChoice.forward` and have been ignored: is_2choice, src, word, instance, zh_dot_type, dot_type_2, eng word, zh_dot_gloss, zh_type_class, type_class, zh_dot_type_2, is_one_ans, pos, __index_level_0__, dot_type_1.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 114\n",
      "  Batch size = 6\n",
      "Saving model checkpoint to prompt-tuning-v2/checkpoint-988\n",
      "Configuration saved in prompt-tuning-v2/checkpoint-988/config.json\n",
      "Model weights saved in prompt-tuning-v2/checkpoint-988/pytorch_model.bin\n",
      "tokenizer config file saved in prompt-tuning-v2/checkpoint-988/tokenizer_config.json\n",
      "Special tokens file saved in prompt-tuning-v2/checkpoint-988/special_tokens_map.json\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `BertPromptForMultipleChoice.forward` and have been ignored: is_2choice, src, word, instance, zh_dot_type, dot_type_2, eng word, zh_dot_gloss, zh_type_class, type_class, zh_dot_type_2, is_one_ans, pos, __index_level_0__, dot_type_1.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 114\n",
      "  Batch size = 6\n",
      "Saving model checkpoint to prompt-tuning-v2/checkpoint-1064\n",
      "Configuration saved in prompt-tuning-v2/checkpoint-1064/config.json\n",
      "Model weights saved in prompt-tuning-v2/checkpoint-1064/pytorch_model.bin\n",
      "tokenizer config file saved in prompt-tuning-v2/checkpoint-1064/tokenizer_config.json\n",
      "Special tokens file saved in prompt-tuning-v2/checkpoint-1064/special_tokens_map.json\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `BertPromptForMultipleChoice.forward` and have been ignored: is_2choice, src, word, instance, zh_dot_type, dot_type_2, eng word, zh_dot_gloss, zh_type_class, type_class, zh_dot_type_2, is_one_ans, pos, __index_level_0__, dot_type_1.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 114\n",
      "  Batch size = 6\n",
      "Saving model checkpoint to prompt-tuning-v2/checkpoint-1140\n",
      "Configuration saved in prompt-tuning-v2/checkpoint-1140/config.json\n",
      "Model weights saved in prompt-tuning-v2/checkpoint-1140/pytorch_model.bin\n",
      "tokenizer config file saved in prompt-tuning-v2/checkpoint-1140/tokenizer_config.json\n",
      "Special tokens file saved in prompt-tuning-v2/checkpoint-1140/special_tokens_map.json\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `BertPromptForMultipleChoice.forward` and have been ignored: is_2choice, src, word, instance, zh_dot_type, dot_type_2, eng word, zh_dot_gloss, zh_type_class, type_class, zh_dot_type_2, is_one_ans, pos, __index_level_0__, dot_type_1.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 114\n",
      "  Batch size = 6\n",
      "Saving model checkpoint to prompt-tuning-v2/checkpoint-1216\n",
      "Configuration saved in prompt-tuning-v2/checkpoint-1216/config.json\n",
      "Model weights saved in prompt-tuning-v2/checkpoint-1216/pytorch_model.bin\n",
      "tokenizer config file saved in prompt-tuning-v2/checkpoint-1216/tokenizer_config.json\n",
      "Special tokens file saved in prompt-tuning-v2/checkpoint-1216/special_tokens_map.json\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `BertPromptForMultipleChoice.forward` and have been ignored: is_2choice, src, word, instance, zh_dot_type, dot_type_2, eng word, zh_dot_gloss, zh_type_class, type_class, zh_dot_type_2, is_one_ans, pos, __index_level_0__, dot_type_1.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 114\n",
      "  Batch size = 6\n",
      "Saving model checkpoint to prompt-tuning-v2/checkpoint-1292\n",
      "Configuration saved in prompt-tuning-v2/checkpoint-1292/config.json\n",
      "Model weights saved in prompt-tuning-v2/checkpoint-1292/pytorch_model.bin\n",
      "tokenizer config file saved in prompt-tuning-v2/checkpoint-1292/tokenizer_config.json\n",
      "Special tokens file saved in prompt-tuning-v2/checkpoint-1292/special_tokens_map.json\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `BertPromptForMultipleChoice.forward` and have been ignored: is_2choice, src, word, instance, zh_dot_type, dot_type_2, eng word, zh_dot_gloss, zh_type_class, type_class, zh_dot_type_2, is_one_ans, pos, __index_level_0__, dot_type_1.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 114\n",
      "  Batch size = 6\n",
      "Saving model checkpoint to prompt-tuning-v2/checkpoint-1368\n",
      "Configuration saved in prompt-tuning-v2/checkpoint-1368/config.json\n",
      "Model weights saved in prompt-tuning-v2/checkpoint-1368/pytorch_model.bin\n",
      "tokenizer config file saved in prompt-tuning-v2/checkpoint-1368/tokenizer_config.json\n",
      "Special tokens file saved in prompt-tuning-v2/checkpoint-1368/special_tokens_map.json\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `BertPromptForMultipleChoice.forward` and have been ignored: is_2choice, src, word, instance, zh_dot_type, dot_type_2, eng word, zh_dot_gloss, zh_type_class, type_class, zh_dot_type_2, is_one_ans, pos, __index_level_0__, dot_type_1.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 114\n",
      "  Batch size = 6\n",
      "Saving model checkpoint to prompt-tuning-v2/checkpoint-1444\n",
      "Configuration saved in prompt-tuning-v2/checkpoint-1444/config.json\n",
      "Model weights saved in prompt-tuning-v2/checkpoint-1444/pytorch_model.bin\n",
      "tokenizer config file saved in prompt-tuning-v2/checkpoint-1444/tokenizer_config.json\n",
      "Special tokens file saved in prompt-tuning-v2/checkpoint-1444/special_tokens_map.json\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `BertPromptForMultipleChoice.forward` and have been ignored: is_2choice, src, word, instance, zh_dot_type, dot_type_2, eng word, zh_dot_gloss, zh_type_class, type_class, zh_dot_type_2, is_one_ans, pos, __index_level_0__, dot_type_1.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 114\n",
      "  Batch size = 6\n",
      "Saving model checkpoint to prompt-tuning-v2/checkpoint-1520\n",
      "Configuration saved in prompt-tuning-v2/checkpoint-1520/config.json\n",
      "Model weights saved in prompt-tuning-v2/checkpoint-1520/pytorch_model.bin\n",
      "tokenizer config file saved in prompt-tuning-v2/checkpoint-1520/tokenizer_config.json\n",
      "Special tokens file saved in prompt-tuning-v2/checkpoint-1520/special_tokens_map.json\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from prompt-tuning-v2/checkpoint-1368 (score: 0.719298243522644).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=1520, training_loss=0.5472685211583188, metrics={'train_runtime': 47.4979, 'train_samples_per_second': 191.587, 'train_steps_per_second': 32.001, 'total_flos': 615881950804344.0, 'train_loss': 0.5472685211583188, 'epoch': 20.0})"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# bert freeze version \n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "9e4a2018-96b2-43a0-aeb2-27129024cec1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set  don't have a corresponding argument in `BertPromptForMultipleChoice.forward` and have been ignored: is_2choice, src, word, instance, zh_dot_type, dot_type_2, eng word, zh_dot_gloss, zh_type_class, type_class, zh_dot_type_2, is_one_ans, pos, __index_level_0__, dot_type_1.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 114\n",
      "  Batch size = 6\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='19' max='19' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [19/19 00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.789947509765625,\n",
       " 'eval_accuracy': 0.719298243522644,\n",
       " 'eval_runtime': 0.2111,\n",
       " 'eval_samples_per_second': 540.073,\n",
       " 'eval_steps_per_second': 90.012,\n",
       " 'epoch': 20.0}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.evaluate(encoded_dataset[\"test\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "afe8e38f-d0ea-4d3f-8d68-0a2ff8b24b4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to ../data/model/pt-nt12-apricot\n",
      "Configuration saved in ../data/model/pt-nt12-apricot/config.json\n",
      "Model weights saved in ../data/model/pt-nt12-apricot/pytorch_model.bin\n",
      "tokenizer config file saved in ../data/model/pt-nt12-apricot/tokenizer_config.json\n",
      "Special tokens file saved in ../data/model/pt-nt12-apricot/special_tokens_map.json\n"
     ]
    }
   ],
   "source": [
    "trainer.save_model(\"../data/models/pt-nt12-apricot\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "4283b769-0a4e-47c5-b3bc-30ce3ac2ac7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mv ../etc/prompt-tuning-v2/Mar12-093217-912/ ../data/models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "397c08f2-7d4c-4613-85d4-95bded3be9ee",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
